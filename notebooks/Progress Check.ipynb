{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I've managed to train a model for a single epoch. Now I can check what (if anything) it has managed to pick up so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = r'C:\\Users\\caleb\\Documents\\Data Science\\welcome-to-night-vale'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(DATA_PATH, 'models')\n",
    "LOG_PATH = os.path.join(ROOT_PATH, 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(MODEL_PATH, 'wtnv-keras-model.hd5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to generate text from random values. To do this, I need to have the same alphabet and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_text(filepath):\n",
    "    '''Load text file from DATA_PATH'''\n",
    "    with open(os.path.join(DATA_PATH, filepath),\n",
    "              'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_alphabet(text):\n",
    "    # lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    # create mapping of unique chars to integers, and a reverse mapping\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    # summarize the loaded data\n",
    "    n_chars = len(text)\n",
    "    n_vocab = len(chars)\n",
    "    \n",
    "    return char_to_int, int_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_processing(text, seq_length=100):\n",
    "\t'''Preprocesses text file for model.\n",
    "\t   Lowercases text, converts to integer arrays of length seq_length.\n",
    "\n",
    "\t   Args:\n",
    "\t  \ttext - text file to be processed\n",
    "\t  \tseq_length - length of character sequences to be considered \n",
    "\t   \t\t\t\t in the training set\n",
    "\t\t\n",
    "\t   Returns:\n",
    "\t\tX - Array of integers representing character sequences from\n",
    "\t\t\tthe training text with length seq_length.\n",
    "\t\t\tX.shape = (n_chars - seq_length, seq_length, 1)\n",
    "\t\ty - Array of integers representing next characters for each\n",
    "\t\t\tsequence in X.\n",
    "\t\t\ty.shape = (n_chars - seq_length, n_vocab)'''\n",
    "\n",
    "\t# lowercase text\n",
    "\ttext = text.lower()\n",
    "\n",
    "\t# create mapping of unique chars to integers, and a reverse mapping\n",
    "\tchars = sorted(list(set(text)))\n",
    "\tchar_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\tint_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\t# summarize the loaded data\n",
    "\tn_chars = len(text)\n",
    "\tn_vocab = len(chars)\n",
    "\tprint(\"Total Characters:\", n_chars)\n",
    "\tprint(\"Total Vocab:\", n_vocab)\n",
    "\n",
    "\t# prepare the dataset of input to output pairs encoded as integers\n",
    "\tdataX = []\n",
    "\tdataY = []\n",
    "\tfor i in range(0, n_chars - seq_length, 1):\n",
    "\t\tseq_in = text[i:i + seq_length]\n",
    "\t\tseq_out = text[i + seq_length]\n",
    "\t\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\t\tdataY.append(char_to_int[seq_out])\n",
    "\n",
    "\tn_patterns = len(dataX)\n",
    "\tprint(\"Total Patterns:\", n_patterns)\n",
    "\n",
    "\t# reshape X to be [samples, time steps, features]\n",
    "\tX = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "\t# normalize\n",
    "\tX = X / n_vocab\n",
    "\n",
    "\t# one hot encode the output variable\n",
    "\ty = np_utils.to_categorical(dataY)\n",
    "\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 1628468\n",
      "Total Vocab: 192\n",
      "Total Patterns: 1628368\n"
     ]
    }
   ],
   "source": [
    "text = load_text('Welcome To Night Vale.txt')\n",
    "char_to_int, int_to_char = get_alphabet(text)\n",
    "n_vocab = len(char_to_int)\n",
    "X, y = pre_processing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat any work in grove park was making way for a new swing set, picnic area, and bloodstone circle, w\n"
     ]
    }
   ],
   "source": [
    "index = random.randint(0, X.shape[0])\n",
    "print(''.join([int_to_char[i] for i in (X[index,:,0] * n_vocab).astype(np.int32)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "з̱ ºzдͯр̳éd9p̩̏aî̜̝(i©̹<̠̥ 5ü8k♫ͨу̮f̃‽̙͚͓͊̐ц:͎͛а̤̾]̫ͬо̻͉͈͂6uэͥ.ьxж/̭̎͗̒♪̄n̞¼ш̲ͮ͒̔ͅâ“̺̣̉̍в-̖̅̀ю‘̦̪ͣ”$\n"
     ]
    }
   ],
   "source": [
    "print(''.join([int_to_char[i] for i in random.sample(range(n_vocab), 100)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i n it  r  sss  d  g \n",
      "j  s  ,  я e  y  s n e i e e  ys \n",
      "j os  r        ssst     g   e c   m   \n",
      "\n",
      "\n",
      "st \n"
     ]
    }
   ],
   "source": [
    "# generate sequence of random characters\n",
    "seq = np.random.choice(range(n_vocab), size=(1, 100, 1))\n",
    "\n",
    "for i in range(1000):    \n",
    "    # predict next character in sequence\n",
    "    next_char = np.random.choice(range(n_vocab), \n",
    "                                 p=model.predict(seq)[0,:])\n",
    "\n",
    "    # append next character, drop first character and reshape\n",
    "    seq = np.append(seq, next_char)[1:].reshape(1,100,1)\n",
    "\n",
    "print(''.join([int_to_char[i] for i in seq[0,:,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-env",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
